{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0005b7f-afad-45de-a24f-bf4d3f161042",
   "metadata": {},
   "source": [
    "The weights used in this notebook are generated by the 'algorithm.py' script.\n",
    "Run it with:\n",
    "\n",
    "```\n",
    "python train --num_iterations 1\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd4b0d69-df03-4839-ac43-65866e28784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "from entmax import sparsemax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2835d8d6-be3d-439b-a0d2-3a92bddc9e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "\n",
    "γ = 0.99 # discount factor\n",
    "α = 1\n",
    "λ = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c129308-a33a-4cba-bf27-ee1954dad34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_alpha(π, α=1):\n",
    "    if α == 1:\n",
    "        return torch.log(π)\n",
    "    else:\n",
    "        return (torch.pow(π, α-1)-1)/(α * (α-1))\n",
    "\n",
    "def Tsallis_Entropy(π, α=1):\n",
    "        return -π * log_alpha(π, α)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4b2115c-0c5f-4610-bb4a-cc1ca3e7552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(path_to_weights):\n",
    "    # actor parameters\n",
    "    actor_weights = {}\n",
    "    for file in os.listdir(path_to_weights):\n",
    "        if 'actor' in file:\n",
    "            param_name = file.replace('actor_', '').replace('.txt', '')\n",
    "            actor_weights[param_name] = np.loadtxt(os.path.join(path_to_weights, file))\n",
    "    \n",
    "    W_actor = actor_weights['simple_fc1.weight']\n",
    "    b_actor = actor_weights['simple_fc1.bias']\n",
    "    \n",
    "    # critic parameters\n",
    "    critic_weights = {}\n",
    "    for file in os.listdir(path_to_weights):\n",
    "        if 'critic' in file:\n",
    "            param_name = file.replace('critic_', '').replace('.txt', '')\n",
    "            critic_weights[param_name] = np.loadtxt(os.path.join(path_to_weights, file))\n",
    "    \n",
    "    W_critic = critic_weights['simple_fc1.weight']\n",
    "    b_critic = critic_weights['simple_fc1.bias']\n",
    "\n",
    "    return {'W_actor': W_actor,\n",
    "            'b_actor': b_actor,\n",
    "            'W_critic': W_critic,\n",
    "            'b_critic': b_critic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1674f008-0944-4704-81a1-e291875c484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor():\n",
    "    def __init__(self, weights, bias):\n",
    "        self.W = torch.tensor(weights, requires_grad=True)\n",
    "        self.b = torch.tensor(bias, requires_grad=True)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        return torch.nn.functional.softmax(self.W @ state + self.b, dim=0)\n",
    "\n",
    "class Critic():\n",
    "    def __init__(self, weights, bias):\n",
    "        self.W = torch.tensor(weights, requires_grad=True)\n",
    "        self.b = torch.tensor(bias, requires_grad=True)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        return self.W @ state + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9de14049-c563-41ef-a5a8-c0f68384dcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = load_weights('../weights')\n",
    "\n",
    "n_actions = len(weights['b_actor'])\n",
    "\n",
    "actor  = Actor(weights['W_actor'], weights['b_actor'])\n",
    "critic = Critic(weights['W_critic'], weights['b_actor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b578ee0-5c2d-4404-a62a-949dd46c6794",
   "metadata": {},
   "source": [
    "Since the $Q_{\\theta}(S_{t}, \\cdot)$ values don't matter when computing $\\nabla_{\\psi}J_{\\pi}(\\psi)$, we can choose a tensor of constant values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd063789-8aea-4baf-818c-8165507f7f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.tensor(np.linspace(1, n_actions, n_actions), requires_grad=False).double()\n",
    "qvals = critic.forward(state).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4b75906-5e2a-4b9f-9c9b-382e64f8b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = actor.forward(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8de8ace-5b6a-42e2-af62-9eda1446f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_term  = policy * qvals\n",
    "entropy_term = Tsallis_Entropy(policy, α) # Shannon Entropy\n",
    "\n",
    "loss = - torch.sum(linear_term + entropy_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cbeaca9-1062-472c-8b80-e4d9b360c0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18d691be-608c-4a65-8d03-fd6eda4ad842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02417415, -0.04834831, -0.07252246, -0.09669661],\n",
       "       [-0.50155346, -1.00310692, -1.50466037, -2.00621383],\n",
       "       [ 0.57248761,  1.14497523,  1.71746284,  2.28995045],\n",
       "       [-0.04676   , -0.09352   , -0.14028001, -0.18704001]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor.W.grad.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dad3a07-ff37-4087-93bd-16aa8537f988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02417415, -0.04834831, -0.07252246, -0.09669661],\n",
       "       [-0.50155346, -1.00310692, -1.50466037, -2.00621383],\n",
       "       [ 0.57248761,  1.14497523,  1.71746284,  2.28995045],\n",
       "       [-0.04676   , -0.09352   , -0.14028001, -0.18704001]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analytical result\n",
    "π = policy.detach().numpy()\n",
    "\n",
    "grad_soft = np.diag(π) - np.outer(π, π)\n",
    "-(qvals.numpy() - np.log(π) - 1) * grad_soft @ np.array([state for i in range(n_actions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fdbf7b8-8c5a-415e-9450-cd5988c72eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname('../'))\n",
    "from algorithm import test_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481c213c-6f50-4532-ab90-750b96d78c1c",
   "metadata": {},
   "source": [
    "# 1 Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee965a22-1260-4cee-b198-b678ffe74021",
   "metadata": {},
   "source": [
    "Environment and Gradient steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3ea80ce-9e2c-41b5-a46d-77a7aae6b2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart nets\n",
    "actor  = Actor(weights['W_actor'], weights['b_actor'])\n",
    "critic = Critic(weights['W_critic'], weights['b_actor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d69250a2-d068-4a8f-8e00-55dbb9698948",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = test_env(n_actions)\n",
    "\n",
    "# initialize environment\n",
    "state = env.reset()\n",
    "\n",
    "# Environment step\n",
    "policy = actor.forward(torch.tensor(state).double())\n",
    "action = torch.argmax(policy.detach(), dim=0)\n",
    "\n",
    "next_state, reward, _, _ = env.step(action)\n",
    "\n",
    "# Gradient step\n",
    "\n",
    "# Critic\n",
    "with torch.no_grad():\n",
    "    next_qvals  = critic.forward(torch.tensor(next_state).double()) \n",
    "    next_policy = actor.forward(torch.tensor(next_state).double())\n",
    "    next_action = torch.argmax(next_policy, dim=0)\n",
    "\n",
    "    target = reward + γ * (next_qvals[next_action] + (λ/α) * log_alpha(next_policy[next_action]))\n",
    "\n",
    "qvals  = critic.forward(torch.tensor(state).double())\n",
    "v_loss = F.mse_loss(qvals[action], target)/2\n",
    "\n",
    "# Actor\n",
    "linear_term  = policy * qvals.detach()\n",
    "entropy_term = Tsallis_Entropy(policy, α) # Shannon Entropy\n",
    "\n",
    "p_loss = - torch.sum(linear_term + entropy_term)\n",
    "\n",
    "# backward pass\n",
    "v_loss.backward()\n",
    "p_loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b00456-64f9-41c3-9bf2-18327bfb2126",
   "metadata": {},
   "source": [
    "### Critic Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03504b4f-bbdc-4ed1-8958-fa0932561513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critic weights' gradient:\n",
      "\n",
      "[[  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [ -4.09226372  -8.18452744 -12.27679116 -16.36905488]\n",
      " [  0.           0.           0.           0.        ]]\n",
      "\n",
      "\n",
      "Critic bias' gradient:\n",
      "\n",
      "[ 0.          0.         -4.09226372  0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Critic weights' gradient:\\n\")\n",
    "print(critic.W.grad.numpy())\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"Critic bias' gradient:\\n\")\n",
    "print(critic.b.grad.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f65f38-8452-4b1c-8f4d-7d061e4c8c90",
   "metadata": {},
   "source": [
    "### Actor Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95596770-476b-4852-9d53-780b0aa640bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor weights' gradient:\n",
      "\n",
      "[[-0.02417415 -0.04834831 -0.07252246 -0.09669661]\n",
      " [-0.50155346 -1.00310692 -1.50466037 -2.00621383]\n",
      " [ 0.57248761  1.14497523  1.71746284  2.28995045]\n",
      " [-0.04676    -0.09352    -0.14028001 -0.18704001]]\n",
      "\n",
      "\n",
      "Actor bias' gradient:\n",
      "\n",
      "[-0.02417415 -0.50155346  0.57248761 -0.04676   ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Actor weights' gradient:\\n\")\n",
    "print(actor.W.grad.numpy())\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(\"Actor bias' gradient:\\n\")\n",
    "print(actor.b.grad.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45378ce9-d4b5-43c8-a806-f1d563b364a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!open ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5944f7dd-8d4b-46ca-80ee-50259eba628f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.11",
   "language": "python",
   "name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
