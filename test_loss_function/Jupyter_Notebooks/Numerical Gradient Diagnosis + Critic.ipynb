{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd4b0d69-df03-4839-ac43-65866e28784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from entmax import sparsemax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4b2115c-0c5f-4610-bb4a-cc1ca3e7552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(path_to_weights):\n",
    "    # actor parameters\n",
    "    actor_weights = {}\n",
    "    for file in os.listdir(path_to_weights):\n",
    "        if 'actor' in file:\n",
    "            param_name = file.replace('actor_', '').replace('.txt', '')\n",
    "            actor_weights[param_name] = np.loadtxt(os.path.join(path_to_weights, file))\n",
    "    \n",
    "    W_actor = actor_weights['simple_fc1.weight']\n",
    "    b_actor = actor_weights['simple_fc1.bias']\n",
    "    \n",
    "    # critic parameters\n",
    "    critic_weights = {}\n",
    "    for file in os.listdir(path_to_weights):\n",
    "        if 'critic' in file:\n",
    "            param_name = file.replace('critic_', '').replace('.txt', '')\n",
    "            critic_weights[param_name] = np.loadtxt(os.path.join(path_to_weights, file))\n",
    "    \n",
    "    W_critic = critic_weights['simple_fc1.weight']\n",
    "    b_critic = critic_weights['simple_fc1.bias']\n",
    "\n",
    "    return {'W_actor': W_actor,\n",
    "            'b_actor': b_actor,\n",
    "            'W_critic': W_critic,\n",
    "            'b_critic': b_critic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1674f008-0944-4704-81a1-e291875c484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor():\n",
    "    def __init__(self, weights, bias):\n",
    "        self.W = torch.tensor(weights, requires_grad=True)\n",
    "        self.b = torch.tensor(bias, requires_grad=True)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        return torch.nn.functional.softmax(self.W @ state + self.b, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9de14049-c563-41ef-a5a8-c0f68384dcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = load_weights('../weights')\n",
    "\n",
    "n_actions = len(weights['b_actor'])\n",
    "\n",
    "actor = Actor(weights['W_actor'], weights['b_actor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b578ee0-5c2d-4404-a62a-949dd46c6794",
   "metadata": {},
   "source": [
    "Since the $Q_{\\theta}(S_{t}, \\cdot)$ values don't matter when computing $\\nabla_{\\psi}J_{\\pi}(\\psi)$, we can choose a tensor of constant values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd063789-8aea-4baf-818c-8165507f7f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "qvals = torch.tensor(np.ones(n_actions), requires_grad=False).double()\n",
    "state = torch.tensor(np.linspace(1, n_actions, n_actions), requires_grad=False).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4b75906-5e2a-4b9f-9c9b-382e64f8b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = actor.forward(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8de8ace-5b6a-42e2-af62-9eda1446f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_term  = policy * qvals\n",
    "entropy_term = -policy * torch.log(policy) # Shannon Entropy\n",
    "\n",
    "loss = - torch.sum(linear_term + entropy_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cbeaca9-1062-472c-8b80-e4d9b360c0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18d691be-608c-4a65-8d03-fd6eda4ad842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03790628, -0.07581256, -0.11371884, -0.15162512],\n",
       "       [-0.17575225, -0.35150449, -0.52725674, -0.70300898],\n",
       "       [ 0.34409185,  0.6881837 ,  1.03227554,  1.37636739],\n",
       "       [-0.13043332, -0.26086665, -0.39129997, -0.52173329]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor.W.grad.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dad3a07-ff37-4087-93bd-16aa8537f988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03790628, -0.07581256, -0.11371884, -0.15162512],\n",
       "       [-0.17575225, -0.35150449, -0.52725674, -0.70300898],\n",
       "       [ 0.34409185,  0.6881837 ,  1.03227554,  1.37636739],\n",
       "       [-0.13043332, -0.26086665, -0.39129997, -0.52173329]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analytical result\n",
    "π = policy.detach().numpy()\n",
    "\n",
    "grad_soft = np.diag(π) - np.outer(π, π)\n",
    "-(qvals.numpy() - np.log(π) - 1) * grad_soft @ np.array([state for i in range(n_actions)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.11",
   "language": "python",
   "name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
